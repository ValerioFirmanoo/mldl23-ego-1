# Domain Adaptation for Egocentric Action Recognition

## Introduction

This project focuses on advancing the field of Egocentric Action Recognition through innovative domain adaptation techniques. By leveraging RGB features extracted from the EPIC KITCHEN DATASET with a 3D-inflated network, we explore different domain adaptation methods to enhance generalization across various domain shifts. Our approach combines adversarial learning modules at different temporal aggregation levels with an attentive mechanism and Minimum Class Confusion loss, achieving significant improvements over baseline models.

## Team Members

- **Valerio Firmano** - Polytechnic of Turin - [valerio.firmano@studenti.polito.it](mailto:valerio.firmano@studenti.polito.it)
- **Filippo Grobbo** - Polytechnic of Turin - [filippo.grobbo@studenti.polito.it](mailto:filippo.grobbo@studenti.polito.it)
- **Matteo Bianco** - Polytechnic of Turin - [matteo.bianco@studenti.polito.it](mailto:matteo.bianco@studenti.polito.it)

## Abstract

The challenge of egocentric action recognition is increasingly significant due to its potential applications in various domains. Our research tackles the issue of domain shift by introducing a novel domain adaptation strategy that not only focuses on aligning feature distributions across domains but also emphasizes on reducing class confusion, leading to a robust improvement in action recognition accuracy.

## Code and Resources

All related code and resources for this project are available in this repository. 

You can access the project code here:
[Project Code](https://github.com/ValerioFirmanoo/mldl23-ego-1/tree/dev)

You can access the final paper here:
[Project Paper](https://github.com/ValerioFirmanoo/mldl23-ego-1/EGOVISION-Action-Recognition.pdf)

## How to Use

Detailed instructions on how to setup, run experiments, and evaluate the model are provided in the `instructions.md` file.

## Results

Our approach demonstrates significant improvement in egocentric action recognition performance across various domain shifts, with an average gain of âˆ¼8% over traditional 'Source Only' methods on the EPIC-KITCHEN dataset. For detailed experimental results, refer to the `experimental_results.md` file.

